{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e252b6f-97a3-4160-a3b2-e83846194909",
   "metadata": {
    "id": "6e252b6f-97a3-4160-a3b2-e83846194909"
   },
   "source": [
    "# Ensemble with Node Similarity Forecasting\n",
    "\n",
    "This notebook demonstrates a forecasting approach called **“Ensemble with Node Similarity”**, using a pre-trained foundation time-series model (*TimesFM*) and multivariate sensor/node data. The goal is to improve forecast accuracy of a target node by blending its own forecast with those of *similar neighbor nodes*.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 Setup\n",
    "\n",
    "- **Libraries**:  \n",
    "  `pandas`, `numpy`, `matplotlib` for data handling/plots;  \n",
    "  `timesfm` for the foundation model;  \n",
    "  `scikit-learn` for error metrics and optional regression if needed.\n",
    "\n",
    "- **Data**:  \n",
    "  CSVs named e.g. `temperature_data_{samp}min_{num_nodes}.csv`, where:  \n",
    "  • `samp` = sampling interval in minutes (e.g. 5, 15, 30, 45, 60),  \n",
    "  • `num_nodes` = number of sensor nodes/time series (e.g. 8, 16, 25).  \n",
    "  Contains datetime (`ds`) and temperature readings per node column.\n",
    "\n",
    "- **Train/Test Splits**:  \n",
    "  Train = from `2018-11-01` to `2018-11-06`.  \n",
    "  Test = from `2018-11-08` to `2018-11-10`.  \n",
    "  Forecast horizon (`p_steps`) = 4 hours worth of points, i.e., `4 * 60 / sampling_min`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Method: `forecast_with_ensemble(...)`\n",
    "\n",
    "### Goal\n",
    "\n",
    "For each target node:\n",
    "\n",
    "1. Compute its own forecast using TimesFM.  \n",
    "2. Compute forecasts for a few other “neighbor” nodes that are *most similar* (by correlation) to the target.  \n",
    "3. Blend the target’s forecast (with fixed weight) with scaled neighbor forecasts, using weights derived from similarity.\n",
    "\n",
    "### How it works (step-by-step)\n",
    "\n",
    "| Step | Operation |\n",
    "|---|---|\n",
    "| **1. Correlation ranking** | Use Pearson correlation (lag-0) among all nodes vs target. Take absolute value to rank highest similarity, regardless of sign. |\n",
    "| **2. Neighbour selection** | Pick up to `n_similar` nodes (excluding the target) as neighbors based on their ranking. If there are fewer available nodes than `n_similar`, use as many as exist. |\n",
    "| **3. Weight construction** | Normalize the correlations of selected neighbors so their weights sum to 1. These are *similarity weights*. |\n",
    "| **4. Base forecast** | Forecast the target node alone using TimesFM over `p_steps`. |\n",
    "| **5. Neighbor forecasts + level adjustment** | For each selected neighbor: forecast with TimesFM, then rescale (via mean ratio) to align neighbor’s scale (level) to target’s mean. |\n",
    "| **6. Blending** | Combine forecasts as:  \n",
    "> `ensemble_forecast = 0.6 * target_forecast + 0.4 * (weighted sum of adjusted neighbor forecasts)` |\n",
    "| **7. Fallback** | If no neighbors exist (or errors happen), just return the target-only forecast. |\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Evaluation Metrics\n",
    "\n",
    "- **MAE** (Mean Absolute Error)  \n",
    "- **RMSE** (Root Mean Squared Error)  \n",
    "- **MAPE** (Mean Absolute Percentage Error)  \n",
    "\n",
    "These are computed over all nodes at each configuration `(num_nodes, sampling_interval)`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Code Walkthrough\n",
    "\n",
    "- `init_timesfm(p_steps)`: initializes the TimesFM model with context/Horizon lengths and preset hyperparameters.  \n",
    "- `forecast_with_ensemble(...)`: implements the ensembling logic as described above.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e91329-90c2-4f24-b3ca-2b09d52c5a83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "08e91329-90c2-4f24-b3ca-2b09d52c5a83",
    "outputId": "13ef2d6a-ac68-4e34-a647-15461185cd74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namanraina/miniconda3/envs/TimesFM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch TimesFM, likely because python version is 3.10.18 (main, Jun  5 2025, 08:37:47) [Clang 14.0.6 ].\n",
      "Requirement already satisfied: jax in ./TimesFM/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: jaxlib<=0.6.2,>=0.6.2 in ./TimesFM/lib/python3.10/site-packages (from jax) (0.6.2)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in ./TimesFM/lib/python3.10/site-packages (from jax) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.26 in ./TimesFM/lib/python3.10/site-packages (from jax) (2.0.1)\n",
      "Requirement already satisfied: opt_einsum in ./TimesFM/lib/python3.10/site-packages (from jax) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in ./TimesFM/lib/python3.10/site-packages (from jax) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "import timesfm\n",
    "!pip install jax\n",
    "!unzip 'Dataset_perSampling_pernodeConfig.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18b506d-d741-4060-a5b0-3f2cce808410",
   "metadata": {
    "id": "c18b506d-d741-4060-a5b0-3f2cce808410"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- NEW: where to save\n",
    "OUT_DIR = Path(\"./outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- NEW: tidy row builder\n",
    "def build_forecast_rows(test_index, approach, nodes, sampling, target_col, y_true_1d, y_pred_1d):\n",
    "    \"\"\"\n",
    "    Returns a list of dict rows for one target series (length = p_steps).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for step, (ts, yt, yp) in enumerate(zip(test_index, y_true_1d, y_pred_1d), start=1):\n",
    "        rows.append({\n",
    "            \"ds\": ts,                         # timestamp for that forecast step\n",
    "            \"approach\": approach,             # e.g., \"Baseline (No Covariates)\"\n",
    "            \"nodes\": nodes,                   # e.g., 8, 16, 25\n",
    "            \"sampling\": sampling,             # minutes (5/15/30/45/60)\n",
    "            \"target\": target_col,             # node/column name\n",
    "            \"step\": step,                     # 1..p_steps\n",
    "            \"y_true\": float(yt),\n",
    "            \"y_pred\": float(yp),\n",
    "        })\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080f4318-40b6-49ab-aa61-b29f9fd41edf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "080f4318-40b6-49ab-aa61-b29f9fd41edf",
    "outputId": "6df06c94-2743-4129-bf57-2d65677173d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-node forecasting comparison...\n",
      "\n",
      "\n",
      "🔄 Testing Approach: Baseline (No Covariates)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 23652.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=5 → MAE=6.38853, RMSE=8.66285, MAPE=0.994%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 90524.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=15 → MAE=9.34823, RMSE=11.27606, MAPE=1.192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 87992.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=30 → MAE=22.93064, RMSE=24.41010, MAPE=2.966%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 76725.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=45 → MAE=8.22409, RMSE=10.20686, MAPE=0.975%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 93902.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=60 → MAE=22.38165, RMSE=25.82326, MAPE=2.973%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 87992.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=5 → MAE=6.85909, RMSE=9.27070, MAPE=1.008%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 88612.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=15 → MAE=11.03376, RMSE=13.27248, MAPE=1.483%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 56679.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=30 → MAE=22.44459, RMSE=23.77225, MAPE=2.845%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 93206.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=45 → MAE=7.78839, RMSE=9.47345, MAPE=0.921%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 85598.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=60 → MAE=21.46845, RMSE=25.04462, MAPE=2.822%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 77195.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=5 → MAE=6.95748, RMSE=9.44145, MAPE=1.025%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 87992.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=15 → MAE=9.81552, RMSE=12.11797, MAPE=1.272%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 81180.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=30 → MAE=21.03804, RMSE=22.96143, MAPE=2.652%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 90524.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=45 → MAE=7.30123, RMSE=8.99792, MAPE=0.860%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 93902.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=60 → MAE=21.58727, RMSE=25.14624, MAPE=2.787%\n",
      "\n",
      "🔄 Testing Approach: Ensemble Similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 83886.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=5 → MAE=3.75346, RMSE=5.05354, MAPE=0.584%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 83330.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=15 → MAE=6.77623, RMSE=8.59362, MAPE=0.843%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 85598.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=30 → MAE=17.76173, RMSE=20.02225, MAPE=2.240%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 88612.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=45 → MAE=5.99140, RMSE=7.06580, MAPE=0.711%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 78643.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=8, samp=60 → MAE=22.05090, RMSE=25.51288, MAPE=2.935%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 85598.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=5 → MAE=4.30093, RMSE=5.73457, MAPE=0.624%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 91180.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=15 → MAE=9.69369, RMSE=11.56990, MAPE=1.258%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 90524.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=30 → MAE=20.00945, RMSE=21.62207, MAPE=2.492%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 85598.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=45 → MAE=6.66894, RMSE=7.60345, MAPE=0.785%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 93902.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=16, samp=60 → MAE=21.11083, RMSE=24.59183, MAPE=2.777%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 83886.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=5 → MAE=5.14311, RMSE=6.50636, MAPE=0.748%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 73156.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=15 → MAE=8.81374, RMSE=10.66176, MAPE=1.126%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 79137.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=30 → MAE=19.13417, RMSE=20.97663, MAPE=2.369%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 41120.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=45 → MAE=6.45546, RMSE=7.51748, MAPE=0.759%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 73156.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nodes=25, samp=60 → MAE=21.35399, RMSE=24.80217, MAPE=2.763%\n",
      "\n",
      "================================================================================\n",
      "📊 MAE Comparison Across Approaches:\n",
      "================================================================================\n",
      "approach        Baseline (No Covariates)  Ensemble Similarity\n",
      "nodes sampling                                               \n",
      "8     5                          6.38853              3.75346\n",
      "      15                         9.34823              6.77623\n",
      "      30                        22.93064             17.76173\n",
      "      45                         8.22409              5.99140\n",
      "      60                        22.38165             22.05090\n",
      "16    5                          6.85909              4.30093\n",
      "      15                        11.03376              9.69369\n",
      "      30                        22.44459             20.00945\n",
      "      45                         7.78839              6.66894\n",
      "      60                        21.46845             21.11083\n",
      "25    5                          6.95748              5.14311\n",
      "      15                         9.81552              8.81374\n",
      "      30                        21.03804             19.13417\n",
      "      45                         7.30123              6.45546\n",
      "      60                        21.58727             21.35399\n",
      "\n",
      "================================================================================\n",
      "📊 RMSE Comparison Across Approaches:\n",
      "================================================================================\n",
      "approach        Baseline (No Covariates)  Ensemble Similarity\n",
      "nodes sampling                                               \n",
      "8     5                          8.66285              5.05354\n",
      "      15                        11.27606              8.59362\n",
      "      30                        24.41010             20.02225\n",
      "      45                        10.20686              7.06580\n",
      "      60                        25.82326             25.51288\n",
      "16    5                          9.27070              5.73457\n",
      "      15                        13.27248             11.56990\n",
      "      30                        23.77225             21.62207\n",
      "      45                         9.47345              7.60345\n",
      "      60                        25.04462             24.59183\n",
      "25    5                          9.44145              6.50636\n",
      "      15                        12.11797             10.66176\n",
      "      30                        22.96143             20.97663\n",
      "      45                         8.99792              7.51748\n",
      "      60                        25.14624             24.80217\n",
      "\n",
      "================================================================================\n",
      "📈 Performance Improvements vs Baseline:\n",
      "================================================================================\n",
      "\n",
      "Ensemble Similarity:\n",
      "  Average MAE Improvement:  +16.95%\n",
      "  Average RMSE Improvement: +17.77%\n",
      "\n",
      "================================================================================\n",
      "🏆 Best Configuration for Each Approach:\n",
      "================================================================================\n",
      "\n",
      "Baseline (No Covariates):\n",
      "  Best config: 8 nodes, 5min sampling\n",
      "  MAE: 6.38853, RMSE: 8.66285\n",
      "\n",
      "Ensemble Similarity:\n",
      "  Best config: 8 nodes, 5min sampling\n",
      "  MAE: 3.75346, RMSE: 5.05354\n",
      "\n",
      "✅ Saved:\n",
      " - Tidy per-config CSVs in: /Users/namanraina/miniconda3/envs/outputs\n",
      " - Global forecasts: /Users/namanraina/miniconda3/envs/outputs/all_forecasts_long.csv\n",
      " - Summary metrics:  /Users/namanraina/miniconda3/envs/outputs/TimesFM_NoCovariates_Ensemble_Similarity.csv\n",
      "\n",
      "🔎 Sample rows (forecasts long):\n",
      "                    ds                  approach  nodes  sampling     target  \\\n",
      "0  2018-11-08 00:00:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "1  2018-11-08 00:05:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "2  2018-11-08 00:10:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "3  2018-11-08 00:15:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "4  2018-11-08 00:20:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "5  2018-11-08 00:25:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "6  2018-11-08 00:30:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "7  2018-11-08 00:35:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "8  2018-11-08 00:40:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "9  2018-11-08 00:45:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "10 2018-11-08 00:50:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "11 2018-11-08 00:55:00  Baseline (No Covariates)      8         5  MAC000025   \n",
      "\n",
      "    step     y_true     y_pred  \n",
      "0      1  13.844852  14.491257  \n",
      "1      2  12.461637  16.736891  \n",
      "2      3  12.594370  19.590696  \n",
      "3      4  12.872548  22.524403  \n",
      "4      5  12.461187  21.535662  \n",
      "5      6  12.305234  18.756235  \n",
      "6      7  12.178452  19.305647  \n",
      "7      8  12.119657  19.643473  \n",
      "8      9  11.788362  16.958668  \n",
      "9     10  11.595557  17.755505  \n",
      "10    11  11.393719  21.460726  \n",
      "11    12  11.471594  20.825525  \n",
      "\n",
      "🔎 Sample rows (summary metrics):\n",
      "                    approach  nodes  sampling        MAE       RMSE      MAPE\n",
      "0   Baseline (No Covariates)      8         5   6.388526   8.662853  0.993998\n",
      "1   Baseline (No Covariates)      8        15   9.348227  11.276057  1.192353\n",
      "2   Baseline (No Covariates)      8        30  22.930641  24.410101  2.965923\n",
      "3   Baseline (No Covariates)      8        45   8.224094  10.206858  0.974516\n",
      "4   Baseline (No Covariates)      8        60  22.381649  25.823261  2.973196\n",
      "5   Baseline (No Covariates)     16         5   6.859092   9.270700  1.007905\n",
      "6   Baseline (No Covariates)     16        15  11.033761  13.272477  1.483086\n",
      "7   Baseline (No Covariates)     16        30  22.444595  23.772251  2.845336\n",
      "8   Baseline (No Covariates)     16        45   7.788387   9.473454  0.921092\n",
      "9   Baseline (No Covariates)     16        60  21.468447  25.044622  2.821554\n",
      "10  Baseline (No Covariates)     25         5   6.957475   9.441453  1.025085\n",
      "11  Baseline (No Covariates)     25        15   9.815516  12.117973  1.272430\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timesfm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup TimesFM pretrained model\n",
    "def init_timesfm(p_steps):\n",
    "    return timesfm.TimesFm(\n",
    "        timesfm.TimesFmHparams(\n",
    "            backend=\"pt\",\n",
    "            context_len=32,\n",
    "            horizon_len=p_steps,\n",
    "            input_patch_len=32,\n",
    "            output_patch_len=128,\n",
    "            use_positional_embedding=False\n",
    "        ),\n",
    "        checkpoint=timesfm.TimesFmCheckpoint(\n",
    "            huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# APPROACH: Ensemble with Node Similarity (Fixed)\n",
    "def forecast_with_ensemble(train, test, target_col, p_steps, tfm, n_similar=3):\n",
    "    \"\"\"\n",
    "    1) Pearson correlation to find similar nodes\n",
    "    2) Forecast target + neighbors\n",
    "    3) Blend (60/40) with correlation weights\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- explicit Pearson ---\n",
    "        correlations = (\n",
    "            train.select_dtypes(include=[np.number])        # numeric cols only\n",
    "                 .corr(method=\"pearson\", min_periods=1)[target_col]  # Pearson is explicit\n",
    "                 .abs()\n",
    "                 .sort_values(ascending=False)\n",
    "        )\n",
    "\n",
    "        available_nodes = len(correlations) - 1\n",
    "        n_use = min(n_similar, available_nodes)\n",
    "\n",
    "        if n_use == 0:\n",
    "            target_hist = train[target_col].values.astype(float)\n",
    "            forecast, _ = tfm.forecast([target_hist], freq=[0])\n",
    "            return forecast[0][:p_steps]\n",
    "\n",
    "        similar_nodes = correlations.index[1:n_use+1].tolist()\n",
    "\n",
    "        # weights from Pearson r (normalized)\n",
    "        weights = correlations[similar_nodes].values\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        # target forecast\n",
    "        target_hist = train[target_col].values.astype(float)\n",
    "        target_forecast, _ = tfm.forecast([target_hist], freq=[0])\n",
    "        target_forecast = target_forecast[0][:p_steps]\n",
    "\n",
    "        ensemble_forecast = target_forecast * 0.6\n",
    "\n",
    "        # neighbor forecasts (level-adjusted by mean ratio)\n",
    "        for node, w in zip(similar_nodes, weights):\n",
    "            node_hist = train[node].values.astype(float)\n",
    "            node_forecast, _ = tfm.forecast([node_hist], freq=[0])\n",
    "\n",
    "            node_mean = train[node].mean()\n",
    "            tgt_mean  = train[target_col].mean()\n",
    "            hist_ratio = (tgt_mean / node_mean) if node_mean != 0 else 1.0\n",
    "\n",
    "            adjusted = node_forecast[0][:p_steps] * hist_ratio\n",
    "            ensemble_forecast += adjusted * w * 0.4\n",
    "\n",
    "        return ensemble_forecast\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ensemble failed for {target_col}: {e}\")\n",
    "        target_hist = train[target_col].values.astype(float)\n",
    "        forecast, _ = tfm.forecast([target_hist], freq=[0])\n",
    "        return forecast[0][:p_steps]\n",
    "\n",
    "print(\"Starting multi-node forecasting comparison...\\n\")\n",
    "\n",
    "results_comparison = []\n",
    "all_rows = []  # NEW: collect tidy rows for all forecasts\n",
    "\n",
    "for approach_name, approach_func in [\n",
    "    (\"Baseline (No Covariates)\", None),\n",
    "    (\"Ensemble Similarity\", forecast_with_ensemble),\n",
    "]:\n",
    "    print(f\"\\n🔄 Testing Approach: {approach_name}\")\n",
    "    approach_results = []\n",
    "\n",
    "    for num_nodes in [8, 16, 25]:\n",
    "        for samp in [5, 15, 30, 45, 60]:\n",
    "            try:\n",
    "                df = pd.read_csv(f\"Dataset_perSampling_pernodeConfig/temperature_data_{samp}min_{num_nodes}.csv\")\n",
    "                df['ds'] = pd.to_datetime(df['ds'])\n",
    "                df = df.set_index('ds').sort_index()\n",
    "                train = df.loc[\"2018-11-01\":\"2018-11-06\"]\n",
    "                test = df.loc[\"2018-11-08\":\"2018-11-10\"]\n",
    "\n",
    "                p_steps = 4 * 60 // samp\n",
    "                tfm = init_timesfm(p_steps)\n",
    "\n",
    "                y_true_mat = []\n",
    "                y_pred_mat = []\n",
    "\n",
    "                # We'll also collect tidy rows per (approach, nodes, sampling) to a file\n",
    "                per_config_rows = []  # NEW\n",
    "\n",
    "                for target_col in train.columns:\n",
    "                    actual = test[target_col].values[:p_steps]\n",
    "\n",
    "                    if approach_func is None:\n",
    "                        # Baseline: standard TimesFM without covariates\n",
    "                        hist = train[target_col].values.astype(float)\n",
    "                        pred, _ = tfm.forecast([hist], freq=[0])\n",
    "                        pred = pred[0][:p_steps]\n",
    "                    else:\n",
    "                        # Use the specified approach\n",
    "                        pred = approach_func(train, test, target_col, p_steps, tfm)\n",
    "\n",
    "                    y_pred_mat.append(pred)\n",
    "                    y_true_mat.append(actual)\n",
    "\n",
    "                    # --- NEW: append tidy rows for this target\n",
    "                    per_config_rows.extend(\n",
    "                        build_forecast_rows(\n",
    "                            test_index=test.index[:p_steps],\n",
    "                            approach=approach_name,\n",
    "                            nodes=num_nodes,\n",
    "                            sampling=samp,\n",
    "                            target_col=target_col,\n",
    "                            y_true_1d=actual,\n",
    "                            y_pred_1d=pred\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                y_true = np.array(y_true_mat).T  # shape [p_steps, n_nodes]\n",
    "                y_pred = np.array(y_pred_mat).T\n",
    "\n",
    "                mae = mean_absolute_error(y_true, y_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "                approach_results.append({\n",
    "                    'approach': approach_name,\n",
    "                    'nodes': num_nodes,\n",
    "                    'sampling': samp,\n",
    "                    'MAE': mae,\n",
    "                    'RMSE': rmse,\n",
    "                    'MAPE': mape\n",
    "                })\n",
    "\n",
    "                print(f\"  nodes={num_nodes}, samp={samp} → MAE={mae:.5f}, RMSE={rmse:.5f}, MAPE={mape:.3f}%\")\n",
    "\n",
    "                # --- NEW: save per-config tidy CSV\n",
    "                per_config_df = pd.DataFrame(per_config_rows)\n",
    "                per_config_path = OUT_DIR / f\"ts_{approach_name.replace(' ', '_')}_nodes{num_nodes}_samp{samp}.csv\"\n",
    "                per_config_df.to_csv(per_config_path, index=False)\n",
    "\n",
    "                # --- also keep for global concatenation\n",
    "                all_rows.extend(per_config_rows)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error for nodes={num_nodes}, samp={samp}: {e}\")\n",
    "                continue\n",
    "\n",
    "    results_comparison.extend(approach_results)\n",
    "\n",
    "# Create comparison dataframe\n",
    "df_comparison = pd.DataFrame(results_comparison)\n",
    "\n",
    "# Pivot for easy comparison\n",
    "pivot_mae = df_comparison.pivot_table(\n",
    "    values='MAE',\n",
    "    index=['nodes', 'sampling'],\n",
    "    columns='approach'\n",
    ")\n",
    "\n",
    "pivot_rmse = df_comparison.pivot_table(\n",
    "    values='RMSE',\n",
    "    index=['nodes', 'sampling'],\n",
    "    columns='approach'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 MAE Comparison Across Approaches:\")\n",
    "print(\"=\"*80)\n",
    "print(pivot_mae.round(5))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 RMSE Comparison Across Approaches:\")\n",
    "print(\"=\"*80)\n",
    "print(pivot_rmse.round(5))\n",
    "\n",
    "# Calculate improvements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📈 Performance Improvements vs Baseline:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_col = \"Baseline (No Covariates)\"\n",
    "if baseline_col in pivot_mae.columns:\n",
    "    for col in pivot_mae.columns:\n",
    "        if col != baseline_col:\n",
    "            mae_improvement = ((pivot_mae[baseline_col] - pivot_mae[col]) / pivot_mae[baseline_col] * 100).mean()\n",
    "            rmse_improvement = ((pivot_rmse[baseline_col] - pivot_rmse[col]) / pivot_rmse[baseline_col] * 100).mean()\n",
    "\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Average MAE Improvement:  {mae_improvement:+.2f}%\")\n",
    "            print(f\"  Average RMSE Improvement: {rmse_improvement:+.2f}%\")\n",
    "\n",
    "# Best configuration per approach\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🏆 Best Configuration for Each Approach:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for approach in df_comparison['approach'].unique():\n",
    "    approach_data = df_comparison[df_comparison['approach'] == approach]\n",
    "    best_config = approach_data.loc[approach_data['MAE'].idxmin()]\n",
    "    print(f\"\\n{approach}:\")\n",
    "    print(f\"  Best config: {best_config['nodes']} nodes, {best_config['sampling']}min sampling\")\n",
    "    print(f\"  MAE: {best_config['MAE']:.5f}, RMSE: {best_config['RMSE']:.5f}\")\n",
    "\n",
    "# --- NEW: save global tidy CSV + metrics CSV and print heads for notebook\n",
    "all_forecasts_df = pd.DataFrame(all_rows)\n",
    "all_forecasts_csv = OUT_DIR / \"all_forecasts_long.csv\"\n",
    "all_forecasts_df.to_csv(all_forecasts_csv, index=False)\n",
    "\n",
    "metrics_csv = OUT_DIR / \"TimesFM_NoCovariates_Ensemble_Similarity.csv\"\n",
    "df_comparison.to_csv(metrics_csv, index=False)\n",
    "\n",
    "print(\"\\n✅ Saved:\")\n",
    "print(f\" - Tidy per-config CSVs in: {OUT_DIR.resolve()}\")\n",
    "print(f\" - Global forecasts: {all_forecasts_csv.resolve()}\")\n",
    "print(f\" - Summary metrics:  {metrics_csv.resolve()}\")\n",
    "\n",
    "print(\"\\n🔎 Sample rows (forecasts long):\")\n",
    "print(all_forecasts_df.head(12))\n",
    "\n",
    "print(\"\\n🔎 Sample rows (summary metrics):\")\n",
    "print(df_comparison.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a88059-e03f-4734-950b-5d2e239b0563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (TimesFM)",
   "language": "python",
   "name": "timesfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
